{"url": "https://huggingface.co/TheBloke/stablelm-zephyr-3b-GGUF/blob/main/stablelm-zephyr-3b.Q6_K.gguf", "gguf_file_path": "c:\\Users\\laelal.halawani\\Desktop\\python\\glai\\glai\\back_end\\model_db\\gguf_models\\stablelm-zephyr-3b.Q6_K.gguf", "model_name": "stablelm-zephyr-3b", "model_quantization": "Q6_K", "description": "StableLM Zephyr 3B is a 3 billion parameter instruction tuned inspired by HugginFaceH4's Zephyr 7B training pipeline this model was trained on a mix of publicly available datasets, synthetic datasets using Direct Preference Optimization (DPO), evaluation for this model based on MT Bench and Alpaca Benchmark", "keywords": ["zephyr", "3b", "instruct", "non-commercial", "research"], "user_tags": {"open": "<|user|>", "close": "<|endoftext|>"}, "ai_tags": {"open": "<|assistant|>", "close": "<|endoftext|>"}, "system_tags": {"open": null, "close": null}, "save_dir": "c:\\Users\\laelal.halawani\\Desktop\\python\\glai\\glai\\back_end\\model_db\\gguf_models"}